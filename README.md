# ğŸ”‹ India Electricity Demand Forecasting System

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Neural Prophet](https://img.shields.io/badge/NeuralProphet-0.7+-green.svg)](https://neuralprophet.com/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

> A production-ready, state-of-the-art electricity demand forecasting system for India and its five electrical regions using Neural Prophet with integrated weather data, holiday effects, and interactive Plotly visualizations.

## ğŸ“‹ Table of Contents

- [Executive Summary](#executive-summary)
- [Key Features](#key-features)
- [Project Structure](#project-structure)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [Implementation Phases](#implementation-phases)
- [Model Architecture](#model-architecture)
- [Interactive Visualizations](#interactive-visualizations)
- [Performance Metrics](#performance-metrics)
- [Contributing](#contributing)
- [License](#license)

## ğŸ¯ Executive Summary

This project implements a sophisticated four-phase electricity demand forecasting system for India's power grid, covering:

- **National Demand**: Country-level aggregate forecasting
- **Regional Forecasts**: Five electrical regions (NR, WR, SR, ER, NER)
- **Advanced ML**: Neural Prophet framework with AR-Net and lagged regressors
- **External Factors**: Weather integration (temperature, precipitation, humidity) and Indian holiday calendars
- **Production-Ready**: Modular architecture, comprehensive logging, error handling, and hyperparameter optimization

### ğŸ“ Developed By

**Pavan Kumar** - Electrical Engineering Graduate specializing in:
- Machine Learning & Deep Learning
- Time-Series Forecasting (Neural Prophet, SARIMA, Prophet)
- Power Systems & Grid Analytics
- Data Science & Interactive Visualizations (Plotly, Matplotlib)

## âœ¨ Key Features

### ğŸ§  Advanced Forecasting
- **Neural Prophet Framework**: Combines traditional time-series decomposition with deep learning
- **Autoregression (AR-Net)**: Captures short-term persistence (configurable 1-28 day lags)
- **Lagged Weather Regressors**: Historical temperature, precipitation, and humidity features
- **Holiday Effects**: Indian national holidays with configurable impact windows
- **COVID-19 Lockdown Modeling**: Explicit structural break handling for March-May 2020

### ğŸ“Š Professional Visualizations
- **Interactive Plotly Dashboards**: Hover tooltips, zoom, pan capabilities
- **Component Decomposition**: Trend, seasonality, holidays, and weather effects
- **Regional Comparisons**: Side-by-side demand pattern analysis
- **Forecast Uncertainty**: Confidence intervals with shaded regions

### ğŸ—ï¸ Production Architecture
- **Modular Design**: Separate modules for data processing, feature engineering, modeling, and evaluation
- **Robust Data Pipeline**: Handles complex CSV structures, missing values, and outliers
- **Automated Weather Integration**: Open-Meteo API for historical meteorological data
- **Time-Aware Cross-Validation**: Rolling-origin validation preventing data leakage
- **Hyperparameter Optimization**: Grid search with Optuna support

## ğŸ“ Project Structure

```
Electricity-Demand-Forecasting/
â”‚
â”œâ”€â”€ requirements.txt                 # All project dependencies
â”œâ”€â”€ README.md                        # This file
â”œâ”€â”€ .gitignore                       # Git ignore rules
â”‚
â”œâ”€â”€ data/                            # Data directory (not tracked)
â”‚   â”œâ”€â”€ raw/                         # Raw CSV files
â”‚   â”œâ”€â”€ processed/                   # Cleaned and merged data
â”‚   â””â”€â”€ external/                    # Weather and holiday data
â”‚
â”œâ”€â”€ src/                             # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚
â”‚   â”œâ”€â”€ data_processing/             # Phase 1: Data Ingestion
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ data_ingestion.py        # CSV loading and cleaning
â”‚   â”‚   â”œâ”€â”€ data_validation.py       # Schema validation
â”‚   â”‚   â””â”€â”€ exploratory_analysis.py  # EDA and decomposition
â”‚   â”‚
â”‚   â”œâ”€â”€ feature_engineering/         # Phase 2: Feature Creation
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ holiday_data.py          # Indian holiday calendar
â”‚   â”‚   â”œâ”€â”€ weather_data.py          # Open-Meteo API integration
â”‚   â”‚   â”œâ”€â”€ feature_creator.py       # HDD, CDD, apparent temp
â”‚   â”‚   â””â”€â”€ regional_mapping.py      # City-to-region coordinates
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                      # Phase 3: Model Development
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ baseline_model.py        # Trend + Seasonality + Events
â”‚   â”‚   â”œâ”€â”€ advanced_model.py        # + AR-Net + Lagged Regressors
â”‚   â”‚   â”œâ”€â”€ global_model.py          # Multi-region global forecaster
â”‚   â”‚   â””â”€â”€ model_utils.py           # Helper functions
â”‚   â”‚
â”‚   â”œâ”€â”€ validation/                  # Phase 4: Validation & Tuning
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ cross_validation.py      # Rolling-origin CV
â”‚   â”‚   â”œâ”€â”€ hyperparameter_tuning.py # Grid search optimization
â”‚   â”‚   â””â”€â”€ metrics.py               # MAE, RMSE, MAPE calculations
â”‚   â”‚
â”‚   â”œâ”€â”€ visualization/               # Interactive Plotting
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ plotly_plots.py          # Interactive hover visualizations
â”‚   â”‚   â”œâ”€â”€ component_plots.py       # Decomposition charts
â”‚   â”‚   â””â”€â”€ comparison_plots.py      # Regional comparisons
â”‚   â”‚
â”‚   â””â”€â”€ utils/                       # Utilities
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logger.py                # Colored logging setup
â”‚       â”œâ”€â”€ config.py                # Configuration management
â”‚       â””â”€â”€ file_utils.py            # I/O helpers
â”‚
â”œâ”€â”€ notebooks/                       # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_feature_engineering.ipynb
â”‚   â”œâ”€â”€ 03_model_training.ipynb
â”‚   â””â”€â”€ 04_results_analysis.ipynb
â”‚
â”œâ”€â”€ scripts/                         # Executable scripts
â”‚   â”œâ”€â”€ download_weather_data.py
â”‚   â”œâ”€â”€ train_models.py
â”‚   â”œâ”€â”€ evaluate_models.py
â”‚   â””â”€â”€ generate_forecasts.py
â”‚
â”œâ”€â”€ models/                          # Saved model checkpoints
â”‚   â”œâ”€â”€ baseline/
â”‚   â”œâ”€â”€ advanced/
â”‚   â””â”€â”€ global/
â”‚
â”œâ”€â”€ outputs/                         # Results
â”‚   â”œâ”€â”€ figures/                     # Plotly HTML and PNG exports
â”‚   â”œâ”€â”€ forecasts/                   # CSV forecast outputs
â”‚   â””â”€â”€ metrics/                     # Performance reports
â”‚
â””â”€â”€ tests/                           # Unit tests
    â”œâ”€â”€ test_data_ingestion.py
    â”œâ”€â”€ test_feature_engineering.py
    â””â”€â”€ test_models.py
```

## ğŸš€ Installation

### Prerequisites

- Python 3.8 or higher
- pip package manager
- (Optional) conda for environment management

### Setup

1. **Clone the repository**

```bash
git clone https://github.com/pavankumar5757/Electricity-Demand-Forecasting.git
cd Electricity-Demand-Forecasting
```

2. **Create virtual environment**

```bash
# Using venv
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# OR using conda
conda create -n demand-forecast python=3.9
conda activate demand-forecast
```

3. **Install dependencies**

```bash
pip install -r requirements.txt
```

4. **Configure data paths** (Optional)

Create a `.env` file:

```
DATA_DIR=./data
OUTPUT_DIR=./outputs
MODEL_DIR=./models
LOG_LEVEL=INFO
```

## âš¡ Quick Start

### Option 1: Run Complete Pipeline

```bash
python scripts/train_models.py --region NR --model advanced
```

### Option 2: Step-by-Step Execution

```python
from src.data_processing.data_ingestion import load_and_clean_demand_data
from src.feature_engineering.weather_data import fetch_weather_data
from src.models.advanced_model import AdvancedNeuralProphetModel

# Load data
df = load_and_clean_demand_data('data/raw/daily_generation_demand.csv')

# Fetch weather
weather_df = fetch_weather_data(start_date='2016-01-01', end_date='2025-11-19')

# Train model
model = AdvancedNeuralProphetModel(region='NR')
model.fit(df, weather_df)

# Generate forecasts
forecast = model.predict(periods=30)
```

### Option 3: Interactive Notebooks

Launch Jupyter:

```bash
jupyter notebook notebooks/03_model_training.ipynb
```

## ğŸ“– Implementation Phases

### Phase 1: Data Preparation âœ…

- **Objective**: Robust data ingestion and cleaning pipeline
- **Key Deliverables**:
  - Multi-header CSV parsing
  - Long-format data transformation
  - Missing value imputation
  - Outlier detection and handling
  - COVID-19 lockdown identification

### Phase 2: Feature Engineering âœ…

- **Objective**: External variable integration
- **Key Deliverables**:
  - Indian holiday calendar (2016-2025)
  - Open-Meteo weather API integration
  - Regional city-to-coordinates mapping (Table 1)
  - Engineered features:
    - Heating Degree Days (HDD)
    - Cooling Degree Days (CDD)
    - Apparent Temperature
    - Temperature Range

### Phase 3: Model Development ğŸ”§

- **Objective**: Neural Prophet model suite
- **Models**:
  1. **Baseline**: Trend + Yearly/Weekly Seasonality + Events
  2. **Advanced**: Baseline + AR-Net (14 lags) + Lagged Weather Regressors
  3. **Global**: Single model for all 6 time series with local trends

### Phase 4: Validation & Optimization ğŸ¯

- **Objective**: Rigorous performance evaluation
- **Key Activities**:
  - Rolling-origin cross-validation
  - Hyperparameter grid search (Table 3)
  - Benchmark comparison (Seasonal Naive)
  - Component interpretation plots

## ğŸ§  Model Architecture

### Neural Prophet Components

```
Forecast = Trend + Seasonality + Events + AR-Net + Lagged_Regressors

Where:
- Trend: Piecewise linear with changepoints
- Seasonality: Fourier series (yearly: 20 terms, weekly: 7 terms)
- Events: Indian holidays + COVID lockdown
- AR-Net: Neural network on past 14 days
- Lagged_Regressors: Weather features (7-day window)
```

### Hyperparameters (Optimized)

| Parameter | Value | Description |
|-----------|-------|-------------|
| `n_lags` | 14 | Autoregressive lookback |
| `ar_reg` | 0.1 | AR-Net L1 regularization |
| `n_changepoints` | 20 | Trend flexibility |
| `trend_reg` | 0.1 | Trend smoothness |
| `yearly_seasonality` | 20 | Yearly Fourier terms |
| `weekly_seasonality` | 7 | Weekly Fourier terms |
| `learning_rate` | 0.01 | Gradient descent step size |

## ğŸ“Š Interactive Visualizations

### Available Plots

1. **Forecast Overview** - Interactive time series with confidence intervals
2. **Component Decomposition** - Trend, seasonality, holidays, weather effects
3. **Regional Comparison** - Side-by-side demand patterns
4. **Feature Importance** - AR-Net lag weights and regressor coefficients
5. **Cross-Validation Results** - Out-of-sample performance across folds

All plots are generated using **Plotly** with:
- âœ¨ Hover tooltips showing exact values
- ğŸ” Zoom and pan capabilities
- ğŸ’¾ Export to HTML and PNG
- ğŸ¨ Professional color schemes

### Example: Generating Interactive Plot

```python
from src.visualization.plotly_plots import create_forecast_plot

fig = create_forecast_plot(forecast, actual=df, region='NR')
fig.show()  # Opens in browser
fig.write_html('outputs/figures/nr_forecast.html')
```

## ğŸ† Performance Metrics

### Evaluation Metrics

```python
MAE = Mean Absolute Error (MU)
RMSE = Root Mean Squared Error (MU)
MAPE = Mean Absolute Percentage Error (%)
```

### Benchmark Comparison

| Model | Region | MAE | RMSE | MAPE |
|-------|--------|-----|------|------|
| Seasonal Naive | NR | 2500 | 3200 | 8.5% |
| Baseline Prophet | NR | 1800 | 2400 | 6.2% |
| **Advanced (Ours)** | **NR** | **1200** | **1600** | **4.1%** |

*Note: Final metrics will be updated after model training*

## ğŸ‘¨â€ğŸ’» Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit changes (`git commit -m 'Add AmazingFeature'`)
4. Push to branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸš€ Future Enhancements

- [ ] Real-time data ingestion pipeline
- [ ] Flask/FastAPI deployment
- [ ] Docker containerization
- [ ] Cloud deployment (AWS/GCP/Azure)
- [ ] Automated retraining scheduler
- [ ] Advanced ensemble methods
- [ ] Probabilistic forecasting

## ğŸ“š References

1. [Neural Prophet Documentation](https://neuralprophet.com/)
2. [Open-Meteo Historical Weather API](https://open-meteo.com/)
3. [Python holidays Library](https://pypi.org/project/holidays/)
4. [Plotly Python Graphing Library](https://plotly.com/python/)

## ğŸ“§ Contact

**Pavan Kumar**
- GitHub: [@pavankumar5757](https://github.com/pavankumar5757)
- LinkedIn: [Your LinkedIn](https://linkedin.com/in/yourprofile)
- Email: your.email@example.com

---

<div align="center">
  <strong>Built with â¤ï¸ for India's Power Grid</strong>
  <br>
  <sub>Leveraging Machine Learning for Sustainable Energy Forecasting</sub>
</div>
